# Complexidade de Algoritmos

## üìö Introdu√ß√£o

Antes de come√ßarmos a estudar os diferentes algoritmos e estruturas de dados que usaremos no mundo da programa√ß√£o competitiva, primeiro precisamos entender como medir a efici√™ncia de um programa, como sabemos que um algoritmo √© melhor do que outro?

√â de suma import√¢ncia conseguirmos responder essa pergunta, j√° que temos um tempo limitado para resolver cada problema (geralmente 1 segundo), e temos que ter uma boa no√ß√£o de qual algoritmo consegue rodar abaixo desse tempo em diferentes tamanhos de entrada.

Para isso, usamos a **complexidade de tempo** e complementarmente a **complexidade de espa√ßo**.

## ‚è≤Ô∏è Complexidade de tempo

A complexidade de tempo de um algoritmo nos informa como o tempo de execu√ß√£o de um algoritmo cresce em fun√ß√£o do tamanho da entrada, se independente da entrada o tempo √© sempre o mesmo, chamamos isso de complexidade de tempo constante, e representamos usando O(1), vamos entender mais sobre isso a seguir.

Por exemplo, considere o seguinte algoritmo:

```py
def soma(n):
    soma = 0
    for i in range(n):
        soma += i
    return soma
```

Esse algoritmo recebe um n√∫mero `n` e retorna a soma de todos os n√∫meros de `0` at√© `n - 1`.

Por exemplo, se `n = 5`, o algoritmo retorna `0 + 1 + 2 + 3 + 4 = 10`.

A complexidade de tempo desse algoritmo √© `O(n)`, pois ele executa `n` opera√ß√µes, uma para cada n√∫mero de `0` at√© `n - 1`, isso √© chamado de crescimento linear.

Chamamos essa nota√ß√£o de **Big O**, ela representa o pior caso de um algoritmo, ou seja, a quantidade m√°xima de opera√ß√µes que um algoritmo pode executar.

Vejamos outro exemplo:

```py
def soma(n):
    soma = 0
    for i in range(n):
        for j in range(n):
            soma += i + j
    return soma
```

Esse algoritmo tamb√©m recebe um n√∫mero `n` por√©m adicionamos um la√ßo de repeti√ß√£o a mais.

Por exemplo, se `n = 3` o algoritmo retorna `(0 + 0) + (0 + 1) + (0 + 2) + (1 + 0) + (1 + 1) + (1 + 2) + (2 + 0) + (2 + 1) + (2 + 2) = 18`.

Podemos perceber ent√£o que a complexidade desse algoritmo √© bem maior do que a do algoritmo anterior, isso se d√° pois cada n√∫mero de `0` at√© `n - 1` √© somado com cada n√∫mero de `0` at√© `n - 1`, isso nos d√° `n * n` opera√ß√µes.

A complexidade de tempo desse algoritmo √© `O(n^2)`, temos um crescimento quadr√°tico.

## üìà Complexidade de tempo de alguns algoritmos

Aqui est√£o alguns exemplos das complexidades de tempo mais comuns:

- **O(1)**: Constante
- **O(log n)**: Logar√≠tmica
- **O(n)**: Linear
- **O(n log n)**: Linear√≠tmica
- **O(n^2)**: Quadr√°tica
- **O(n^3)**: C√∫bica
- **O(2^n)**: Exponencial

√â importante se atentar a complexidade de tempo de um algoritmo, pois ela pode ser a diferen√ßa entre um algoritmo que roda em 1 segundo e um que roda em 1 minuto, como podemos ver no gr√°fico abaixo:

<figure><img src="https://www.raebear.net/media/2017/12/jIGhf.png" alt="Gr√°fico de complexidades"><figcaption></figcaption></figure>

Ao longo da nossa jornada, vamos estudar algoritmos que possuem complexidades de tempo diferentes, levando em conta os diferentes problemas que vamos enfrentar.

## üíÄ Piores complexidades poss√≠veis por tamanho de entrada

Como vimos no gr√°fico acima, vamos tentar evitar ao m√°ximo algoritmos com complexidades grandes, tais como `O(n^2)`, dito isso, precisamos entender que nem sempre isso √© poss√≠vel, e que em alguns casos, algoritmos com complexidades maiores s√£o necess√°rios.

Vamos pensar em um exerc√≠cio que nos pe√ßa pra achar o menor valor em um vetor, qual a menor complexidade poss√≠vel para esse problema?

A menor complexidade poss√≠vel √© `O(n)`! pois precisamos olhar para cada elemento do vetor para saber qual √© o menor valor, n√£o tem como fazer isso sem olhar para cada elemento, veremos problemas muito mais complicados que esse mais para frente, e teremos que usar algoritmos com complexidades ainda piores, assim, √© importante entender qual complexidade √© aceit√°vel levando em conta o tempo dispon√≠vel e o tamanho da entrada, para isso, consulte a tabela abaixo:

<figure><img src="../assets/piores-compl.png" alt="Piores complexidades aceit√°veis"><figcaption></figcaption></figure>

Para cada tamanho de entrada $n$, temos as piores complexidades que s√£o aceit√°veis para passar o problema.

Geralmente, uma regra para 1s de time limit √© multiplicar o tamanho m√°ximo na complexidade. Se for menor que 10‚Å∏ passa tranquilamente, se for na casa do 10‚Å∏, passa apertado dependendo da sua implementa√ß√£o, se for maior, dificilmente passa.

Por exemplo, se o tamanho de $n$ √© 400 e a complexidade for `O(n^3)`, ent√£o 400¬≥ = 6.4 \* 10‚Å∑, o que significa que o algoritmo deve passar o problema.

## üìà Complexidade de espa√ßo

Normalmente, nas competi√ß√µes de programa√ß√£o, mem√≥ria n√£o √© algo que nos preocupamos muito, j√° que o limite geralmente √© bem alto, entretanto, √© importante entender tamb√©m a complexidade de espa√ßo de um algoritmo, pois ainda sim, ela pode ser um fator limitante.

Por exemplo, considere o seguinte algoritmo:

```py
def soma(n):
    numeros = [i for i in range(n)]
    soma = 0
    for i in numeros:
        soma += i
    return soma
```

Esse algoritmo recebe um n√∫mero `n` e retorna a soma de todos os n√∫meros de `0` at√© `n - 1`, usando uma lista para armazenar os n√∫meros.

A complexidade de espa√ßo desse algoritmo √© `O(n)`, pois ele ocupa `n` posi√ß√µes na mem√≥ria, uma para cada n√∫mero de `0` at√© `n - 1`.

Vejamos outro exemplo:

```py
def soma(n):
    numeros = [[i for i in range(n)] for j in range(n)]
    soma = 0
    for i in numeros[0]:
        soma += i
    return soma
```

Note que esse algoritmo tamb√©m recebe um n√∫mero `n` e tamb√©m retorna a soma de todos os n√∫meros de `0` at√© `n - 1`, por√©m usamos uma matriz para armazenar os n√∫meros, cada linha da matriz √© um vetor de `0` at√© `n - 1`, estamos consumindo mais mem√≥ria e tendo o mesmo resultado.

Isso nos d√° uma complexidade de espa√ßo de `O(n^2)`, pois ele ocupa `n * n` posi√ß√µes na mem√≥ria, cada n√∫mero de `0` at√© `n - 1` √© armazenado `n - 1` vezes, podemos visualizar isso rodando os dois exemplos acima e printando a vari√°vel `numeros`, assim como o resultado da soma.

**Exemplo 1**

```bash
soma(10)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
45
```

**Exemplo 2**

```bash
soma(10)
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
45
```

Perceba que nesse exemplo simples, estamos gastando mais mem√≥ria sem necessidade, geralmente isso n√£o √© um problema, e as vezes at√© usamos mais mem√≥ria para alcan√ßar um desempenho melhor, mas √© importante entender que isso tamb√©m √© um fator a ser considerado, e que pode nos afetar negativamente caso sejamos descuidados.
